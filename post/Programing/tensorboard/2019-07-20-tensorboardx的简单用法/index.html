<!DOCTYPE html>
<html
  lang="en"
  itemscope
  itemtype="http://schema.org/WebPage"
>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <title>
          tensorboardX的用法 - Yuanye Ma&#39;s Blog
        </title>
    

<meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=yes"/>

<meta name="MobileOptimized" content="width"/>
<meta name="HandheldFriendly" content="true"/>


<meta name="applicable-device" content="pc,mobile">

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">

<meta name="mobile-web-app-capable" content="yes">

<meta name="author" content="Yuanye Ma" />
  <meta name="description" content="pytorch&#43;tensorboardX 简单总结一下tensorboardX的用法。 import numpy as np from tensorboardX import SummaryWriter write = SummaryWriter() for epoch in range(100): write.add_scalar(&amp;#39;scale/test&amp;#39;, np.random.rand(), epoch) write.add_scalars(&amp;#39;scale/scales_test&amp;#39;, {&amp;#39;xsinx&amp;#39;:epoch*np.sin(epoch), &amp;#39;xcosx&amp;#39; : epoch*np.cos(epoch)}, epoch) write.close() 在终端中运行上边代码:python ./ten" />

  <meta name="keywords" content="Hugo, theme, jane" />






<meta name="generator" content="Hugo 0.125.4" />


<link rel="canonical" href="http://0.0.0.0:1313/post/programing/tensorboard/2019-07-20-tensorboardx%E7%9A%84%E7%AE%80%E5%8D%95%E7%94%A8%E6%B3%95/" />





<link rel="icon" href="/favicon.ico" />











<link rel="stylesheet" href="/sass/jane.min.e826e860368147e5a6685e686355e4d7789023c18c9ea2e78b35f6786ce92736.css" integrity="sha256-6CboYDaBR&#43;WmaF5oY1Xk13iQI8GMnqLnizX2eGzpJzY=" media="screen" crossorigin="anonymous">







<meta property="og:url" content="http://0.0.0.0:1313/post/programing/tensorboard/2019-07-20-tensorboardx%E7%9A%84%E7%AE%80%E5%8D%95%E7%94%A8%E6%B3%95/">
  <meta property="og:site_name" content="Yuanye Ma&#39;s Blog">
  <meta property="og:title" content="tensorboardX的用法">
  <meta property="og:description" content="pytorch&#43;tensorboardX 简单总结一下tensorboardX的用法。 import numpy as np from tensorboardX import SummaryWriter write = SummaryWriter() for epoch in range(100): write.add_scalar(&#39;scale/test&#39;, np.random.rand(), epoch) write.add_scalars(&#39;scale/scales_test&#39;, {&#39;xsinx&#39;:epoch*np.sin(epoch), &#39;xcosx&#39; : epoch*np.cos(epoch)}, epoch) write.close() 在终端中运行上边代码:python ./ten">
  <meta property="og:locale" content="en">
  <meta property="og:type" content="article">
    <meta property="article:section" content="post">
    <meta property="article:published_time" content="2019-04-15T16:01:23+08:00">
    <meta property="article:modified_time" content="2019-04-15T16:01:23+08:00">
    <meta property="article:tag" content="TensorFlow">
    <meta property="article:tag" content="TensorBoardX">

  <meta itemprop="name" content="tensorboardX的用法">
  <meta itemprop="description" content="pytorch&#43;tensorboardX 简单总结一下tensorboardX的用法。 import numpy as np from tensorboardX import SummaryWriter write = SummaryWriter() for epoch in range(100): write.add_scalar(&#39;scale/test&#39;, np.random.rand(), epoch) write.add_scalars(&#39;scale/scales_test&#39;, {&#39;xsinx&#39;:epoch*np.sin(epoch), &#39;xcosx&#39; : epoch*np.cos(epoch)}, epoch) write.close() 在终端中运行上边代码:python ./ten">
  <meta itemprop="datePublished" content="2019-04-15T16:01:23+08:00">
  <meta itemprop="dateModified" content="2019-04-15T16:01:23+08:00">
  <meta itemprop="wordCount" content="1893">
  <meta itemprop="keywords" content="TensorFlow,TensorBoardX"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="tensorboardX的用法">
<meta name="twitter:description" content="pytorch&#43;tensorboardX 简单总结一下tensorboardX的用法。 import numpy as np from tensorboardX import SummaryWriter write = SummaryWriter() for epoch in range(100): write.add_scalar(&#39;scale/test&#39;, np.random.rand(), epoch) write.add_scalars(&#39;scale/scales_test&#39;, {&#39;xsinx&#39;:epoch*np.sin(epoch), &#39;xcosx&#39; : epoch*np.cos(epoch)}, epoch) write.close() 在终端中运行上边代码:python ./ten">

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->




  </head>
  <body>
    <div id="back-to-top"></div>

    <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/" class="logo">功不唐捐</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <li class="mobile-menu-item">
        
          
          
            <a class="menu-item-link" href="http://0.0.0.0:1313/">Home</a>
          
        
      </li><li class="mobile-menu-item">
        
          
          
            <a class="menu-item-link" href="http://0.0.0.0:1313/post/">Archives</a>
          
        
      </li><li class="mobile-menu-item">
        
          
          
            <a class="menu-item-link" href="http://0.0.0.0:1313/tags/">Tags</a>
          
        
      </li><li class="mobile-menu-item">
        
          
          
            <a class="menu-item-link" href="http://0.0.0.0:1313/categories/">Categories</a>
          
        
      </li><li class="mobile-menu-item">
        
          
          
            <a class="menu-item-link" href="http://0.0.0.0:1313/about/">About</a>
          
        
      </li>
    

    
  </ul>
</nav>


    
      






  <link rel="stylesheet" href="/lib/photoswipe/photoswipe.min.css" />
  <link rel="stylesheet" href="/lib/photoswipe/default-skin/default-skin.min.css" />




<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

<div class="pswp__bg"></div>

<div class="pswp__scroll-wrap">
    
    <div class="pswp__container">
      <div class="pswp__item"></div>
      <div class="pswp__item"></div>
      <div class="pswp__item"></div>
    </div>
    
    <div class="pswp__ui pswp__ui--hidden">
    <div class="pswp__top-bar">
      
      <div class="pswp__counter"></div>
      <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
      <button class="pswp__button pswp__button--share" title="Share"></button>
      <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
      <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>
      
      
      <div class="pswp__preloader">
        <div class="pswp__preloader__icn">
          <div class="pswp__preloader__cut">
            <div class="pswp__preloader__donut"></div>
          </div>
        </div>
      </div>
    </div>
    <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
      <div class="pswp__share-tooltip"></div>
    </div>
    <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
    </button>
    <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
    </button>
    <div class="pswp__caption">
      <div class="pswp__caption__center"></div>
    </div>
    </div>
    </div>
</div>

    

    

    <header id="header" class="header">
      <div class="logo-wrapper">
  <a href="/" class="logo">
    
      功不唐捐
    
  </a>
</div>

<nav class="site-navbar">
  <ul id="menu" class="menu">
    
    
        <li class="menu-item">
        
          
          
            <a class="menu-item-link" href="http://0.0.0.0:1313/">Home</a>
          

        

      </li>
    
        <li class="menu-item">
        
          
          
            <a class="menu-item-link" href="http://0.0.0.0:1313/post/">Archives</a>
          

        

      </li>
    
        <li class="menu-item">
        
          
          
            <a class="menu-item-link" href="http://0.0.0.0:1313/tags/">Tags</a>
          

        

      </li>
    
        <li class="menu-item">
        
          
          
            <a class="menu-item-link" href="http://0.0.0.0:1313/categories/">Categories</a>
          

        

      </li>
    
        <li class="menu-item">
        
          
          
            <a class="menu-item-link" href="http://0.0.0.0:1313/about/">About</a>
          

        

      </li>
    

    
    

    
  </ul>
</nav>

    </header>

    <div id="mobile-panel">
      <main id="main" class="main bg-llight wallpaper">
        <div class="content-wrapper">
    <div id="content" class="content">
      <article class="post">
        
        <header class="post-header">
          <h1 class="post-title">tensorboardX的用法</h1>
          

          <div class="post-meta">
  <div class="post-meta-author">
    by
      <a href="/about">
        <span class="post-meta-author-name">
          Yuanye Ma
        </span>
      </a>
    
  </div>

  <div class="post-meta-time">
    <time datetime="2019-04-15">
      2019-04-15
    </time>
  </div>

  


  <div class="post-meta__right">
    

    <div class="post-meta-category">
        <a href="http://0.0.0.0:1313/categories/programing/"> Programing </a>
          
      </div>


    
    


    
    
  </div>
</div>

        </header>

        
        <div class="post-content">
          <h1 id="pytorchtensorboardx">pytorch+tensorboardX</h1>
<p>简单总结一下tensorboardX的用法。</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> numpy <span style="color:#66d9ef">as</span> np 
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> tensorboardX <span style="color:#f92672">import</span> SummaryWriter
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>write <span style="color:#f92672">=</span> SummaryWriter()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> epoch <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">100</span>):
</span></span><span style="display:flex;"><span>    write<span style="color:#f92672">.</span>add_scalar(<span style="color:#e6db74">&#39;scale/test&#39;</span>, np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>rand(), epoch)
</span></span><span style="display:flex;"><span>    write<span style="color:#f92672">.</span>add_scalars(<span style="color:#e6db74">&#39;scale/scales_test&#39;</span>, {<span style="color:#e6db74">&#39;xsinx&#39;</span>:epoch<span style="color:#f92672">*</span>np<span style="color:#f92672">.</span>sin(epoch), <span style="color:#e6db74">&#39;xcosx&#39;</span> : epoch<span style="color:#f92672">*</span>np<span style="color:#f92672">.</span>cos(epoch)}, epoch)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>write<span style="color:#f92672">.</span>close()
</span></span></code></pre></div><p>在终端中运行上边代码:<code>python ./tensorboard_scales.py</code>，查看代码目录下多了一个<code>runs</code>的目录，里边保存的就是代码运行时的数据。</p>
<p><img alt="01" src="01.png"></p>
<p>再使用<code>tensorboard --logdir runs</code>,在浏览器地址栏输入<code>ip_address:6006</code>就能看到图像。</p>
<p><img alt="04" src="04.png"></p>
<p>此时再次运行代码，再查看目录结构，会发现又多了一些目录，这是因为tensorboard会保存几个历史版本。这个功能很好用，可以通过点击左下角的复选框勾选要对比的曲线，进而对比模型的性能。</p>
<p><img alt="02" src="02.png"></p>
<p>试试<code>graph</code></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> torch
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> torch.nn <span style="color:#66d9ef">as</span> nn
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> torch.nn.functional <span style="color:#66d9ef">as</span> F
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> tensorboardX <span style="color:#f92672">import</span> SummaryWriter
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">Net1</span>(nn<span style="color:#f92672">.</span>Module):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> __init__(self):
</span></span><span style="display:flex;"><span>        super(Net1, self)<span style="color:#f92672">.</span>__init__()
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>conv1 <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Conv2d(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">10</span>, kernel_size<span style="color:#f92672">=</span><span style="color:#ae81ff">5</span>)
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>conv2 <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Conv2d(<span style="color:#ae81ff">10</span>, <span style="color:#ae81ff">20</span>, kernel_size<span style="color:#f92672">=</span><span style="color:#ae81ff">5</span>)
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>conv2_drop <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Dropout2d()
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>fc1 <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Linear(<span style="color:#ae81ff">320</span>, <span style="color:#ae81ff">50</span>)
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>fc2 <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Linear(<span style="color:#ae81ff">50</span>, <span style="color:#ae81ff">10</span>)
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>bn <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>BatchNorm2d(<span style="color:#ae81ff">20</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">forward</span>(self, x):
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> F<span style="color:#f92672">.</span>max_pool2d(self<span style="color:#f92672">.</span>conv1(x), <span style="color:#ae81ff">2</span>)
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> F<span style="color:#f92672">.</span>relu(x) <span style="color:#f92672">+</span> F<span style="color:#f92672">.</span>relu(<span style="color:#f92672">-</span>x)
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> F<span style="color:#f92672">.</span>relu(F<span style="color:#f92672">.</span>max_pool2d(self<span style="color:#f92672">.</span>conv2_drop(self<span style="color:#f92672">.</span>conv2(x)), <span style="color:#ae81ff">2</span>))
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>bn(x)
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> x<span style="color:#f92672">.</span>view(<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">320</span>)
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> F<span style="color:#f92672">.</span>relu(self<span style="color:#f92672">.</span>fc1(x))
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> F<span style="color:#f92672">.</span>dropout(x, training<span style="color:#f92672">=</span>self<span style="color:#f92672">.</span>training)
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>fc2(x)
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> F<span style="color:#f92672">.</span>softmax(x, dim<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> x
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>dummy_input <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>rand(<span style="color:#ae81ff">13</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">28</span>, <span style="color:#ae81ff">28</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>model <span style="color:#f92672">=</span> Net1()
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">with</span> SummaryWriter(comment<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;Net1&#39;</span>) <span style="color:#66d9ef">as</span> w:
</span></span><span style="display:flex;"><span>    w<span style="color:#f92672">.</span>add_graph(model, (dummy_input,))
</span></span></code></pre></div><p>在运行的时候报错了。</p>
<p><img alt="error" src="error.png"></p>
<p>上网搜索了一番说是<code>pytorch</code>版本的问题，为了跑写好的强化学习的代码，我用的是比较老的<code>0.4.0</code>版本的，回头有机会测一下<code>pytorch 1.0+</code>的看可不可以用。</p>
<h2 id="总结一下tensorboardx的用法">总结一下TensorboardX的用法</h2>
<ul>
<li>声明一个<code>SummaryWriter()</code>对象，<code>log_dir</code>参数能指定log文件保存的路径。</li>
<li>然后使用<code>add_xxx()</code>函数向log中添加内容，<code>xxx</code>可以是<code>scalar</code>, <code>image</code>, <code>figure</code>, <code>histogram</code>, <code>audio</code>, <code>text</code>, <code>graph</code>, <code>onnx_graph</code>, <code>embedding</code>, <code>pr_curve</code>, <code>mesh</code>, <code>hyper-parameters</code> and <code>video</code>，<a href="https://github.com/lanpa/tensorboardX">详情参见</a>或者<a href="https://tensorboardx.readthedocs.io/en/latest/tensorboard.html">tensorboardX</a>。</li>
<li>关闭<code>SummaryWriter()</code>对象</li>
<li>使用<code>tensorboard --logdir</code>命令启动<code>tensorboard</code></li>
<li>在浏览器里查看输出。</li>
</ul>
<h1 id="tensorflowtensorboard">TensorFlow+TensorBoard</h1>
<p><a href="https://blog.csdn.net/sinat_33761963/article/details/62433234">参考这篇blog</a></p>
<h2 id="总结一下使用的步骤">总结一下使用的步骤</h2>
<ol>
<li>
<p>建立一个计算图（Graph）</p>
</li>
<li>
<p>确定要在Graph中的哪些节点放置summary operations（即要在tensorboard中观察哪些数据）</p>
<ol>
<li><code>tf.summary.scalar</code> - 记录标量</li>
<li><code>tf.summary.histogram</code> - 记录数据的直方图</li>
<li><code>tf.summary.image</code> - 记录图片</li>
<li><code>tf.summary.audio</code> - 记录音频</li>
<li><code>tf.summary.graph</code> - 记录计算图结构</li>
<li><code>tf.summary.distribution</code> - 记录数据分布</li>
<li><code>tf.summary.embeddings</code> - 记录嵌入向量</li>
<li><code>tf.summary.text</code> - 记录文本</li>
</ol>
</li>
<li>
<p>使用<code>tf.summary.merge_all</code>将所有summary operations合并为一个operation</p>
</li>
<li>
<p>运行3中合并之后的operation:<code>summary = sess.run(all_summary)</code></p>
</li>
<li>
<p>声明一个<code>FileWriter</code>对象：<code>writer = tf.summary.FileWriter(&quot;./train&quot;, graph)</code> #如果有graph参数，可以在tensorboard中查看graph的结构。</p>
</li>
<li>
<p>使用<code>tf.summary.FileWriter</code>将数据写入本地磁盘: <code>writer.add_summary(summary, steps)</code></p>
</li>
<li>
<p>运行程序后，使用<code>tensorboard --logdir=logdir</code>启动tensorboard,然后在浏览器中查看。</p>
</li>
</ol>
<h2 id="参考代码">参考代码</h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> tensorflow <span style="color:#66d9ef">as</span> tf
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> tensorflow.examples.tutorials.mnist <span style="color:#f92672">import</span> input_data
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>max_steps <span style="color:#f92672">=</span> <span style="color:#ae81ff">1000</span>  <span style="color:#75715e"># 最大迭代次数</span>
</span></span><span style="display:flex;"><span>learning_rate <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.001</span>   <span style="color:#75715e"># 学习率</span>
</span></span><span style="display:flex;"><span>dropout <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.9</span>   <span style="color:#75715e"># dropout时随机保留神经元的比例</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>data_dir <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;./&#39;</span>   <span style="color:#75715e"># 样本数据存储的路径</span>
</span></span><span style="display:flex;"><span>log_dir <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;./&#39;</span>    <span style="color:#75715e"># 输出日志保存的路径</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>mnist <span style="color:#f92672">=</span> input_data<span style="color:#f92672">.</span>read_data_sets(data_dir, one_hot<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>sess <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>InteractiveSession()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">with</span> tf<span style="color:#f92672">.</span>name_scope(<span style="color:#e6db74">&#39;input&#39;</span>):
</span></span><span style="display:flex;"><span>    x <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>placeholder(tf<span style="color:#f92672">.</span>float32, [<span style="color:#66d9ef">None</span>, <span style="color:#ae81ff">784</span>], name<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;x-input&#39;</span>)
</span></span><span style="display:flex;"><span>    y_ <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>placeholder(tf<span style="color:#f92672">.</span>float32, [<span style="color:#66d9ef">None</span>, <span style="color:#ae81ff">10</span>], name<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;y-input&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">with</span> tf<span style="color:#f92672">.</span>name_scope(<span style="color:#e6db74">&#39;input_reshape&#39;</span>):
</span></span><span style="display:flex;"><span>    image_shaped_input <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>reshape(x, [<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">28</span>, <span style="color:#ae81ff">28</span>, <span style="color:#ae81ff">1</span>])
</span></span><span style="display:flex;"><span>    tf<span style="color:#f92672">.</span>summary<span style="color:#f92672">.</span>image(<span style="color:#e6db74">&#39;input&#39;</span>, image_shaped_input, <span style="color:#ae81ff">10</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">weight_variable</span>(shape):
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;&#34;&#34;Create a weight variable with appropriate initialization.&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    initial <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>truncated_normal(shape, stddev<span style="color:#f92672">=</span><span style="color:#ae81ff">0.1</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> tf<span style="color:#f92672">.</span>Variable(initial)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">bias_variable</span>(shape):
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;&#34;&#34;Create a bias variable with appropriate initialization.&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    initial <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>constant(<span style="color:#ae81ff">0.1</span>, shape<span style="color:#f92672">=</span>shape)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> tf<span style="color:#f92672">.</span>Variable(initial)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">variable_summaries</span>(var):
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;&#34;&#34;Attach a lot of summaries to a Tensor (for TensorBoard visualization).&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">with</span> tf<span style="color:#f92672">.</span>name_scope(<span style="color:#e6db74">&#39;summaries&#39;</span>):
</span></span><span style="display:flex;"><span>      <span style="color:#75715e"># 计算参数的均值，并使用tf.summary.scaler记录</span>
</span></span><span style="display:flex;"><span>      mean <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>reduce_mean(var)
</span></span><span style="display:flex;"><span>      tf<span style="color:#f92672">.</span>summary<span style="color:#f92672">.</span>scalar(<span style="color:#e6db74">&#39;mean&#39;</span>, mean)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>      <span style="color:#75715e"># 计算参数的标准差</span>
</span></span><span style="display:flex;"><span>      <span style="color:#66d9ef">with</span> tf<span style="color:#f92672">.</span>name_scope(<span style="color:#e6db74">&#39;stddev&#39;</span>):
</span></span><span style="display:flex;"><span>        stddev <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>sqrt(tf<span style="color:#f92672">.</span>reduce_mean(tf<span style="color:#f92672">.</span>square(var <span style="color:#f92672">-</span> mean)))
</span></span><span style="display:flex;"><span>      <span style="color:#75715e"># 使用tf.summary.scaler记录记录下标准差，最大值，最小值</span>
</span></span><span style="display:flex;"><span>      tf<span style="color:#f92672">.</span>summary<span style="color:#f92672">.</span>scalar(<span style="color:#e6db74">&#39;stddev&#39;</span>, stddev)
</span></span><span style="display:flex;"><span>      tf<span style="color:#f92672">.</span>summary<span style="color:#f92672">.</span>scalar(<span style="color:#e6db74">&#39;max&#39;</span>, tf<span style="color:#f92672">.</span>reduce_max(var))
</span></span><span style="display:flex;"><span>      tf<span style="color:#f92672">.</span>summary<span style="color:#f92672">.</span>scalar(<span style="color:#e6db74">&#39;min&#39;</span>, tf<span style="color:#f92672">.</span>reduce_min(var))
</span></span><span style="display:flex;"><span>      <span style="color:#75715e"># 用直方图记录参数的分布</span>
</span></span><span style="display:flex;"><span>      tf<span style="color:#f92672">.</span>summary<span style="color:#f92672">.</span>histogram(<span style="color:#e6db74">&#39;histogram&#39;</span>, var)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">nn_layer</span>(input_tensor, input_dim, output_dim, layer_name, act<span style="color:#f92672">=</span>tf<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>relu):
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;&#34;&#34;Reusable code for making a simple neural net layer.
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    It does a matrix multiply, bias add, and then uses relu to nonlinearize.
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    It also sets up name scoping so that the resultant graph is easy to read,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    and adds a number of summary ops.
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 设置命名空间</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">with</span> tf<span style="color:#f92672">.</span>name_scope(layer_name):
</span></span><span style="display:flex;"><span>      <span style="color:#75715e"># 调用之前的方法初始化权重w，并且调用参数信息的记录方法，记录w的信息</span>
</span></span><span style="display:flex;"><span>      <span style="color:#66d9ef">with</span> tf<span style="color:#f92672">.</span>name_scope(<span style="color:#e6db74">&#39;weights&#39;</span>):
</span></span><span style="display:flex;"><span>        weights <span style="color:#f92672">=</span> weight_variable([input_dim, output_dim])
</span></span><span style="display:flex;"><span>        variable_summaries(weights)
</span></span><span style="display:flex;"><span>      <span style="color:#75715e"># 调用之前的方法初始化权重b，并且调用参数信息的记录方法，记录b的信息</span>
</span></span><span style="display:flex;"><span>      <span style="color:#66d9ef">with</span> tf<span style="color:#f92672">.</span>name_scope(<span style="color:#e6db74">&#39;biases&#39;</span>):
</span></span><span style="display:flex;"><span>        biases <span style="color:#f92672">=</span> bias_variable([output_dim])
</span></span><span style="display:flex;"><span>        variable_summaries(biases)
</span></span><span style="display:flex;"><span>      <span style="color:#75715e"># 执行wx+b的线性计算，并且用直方图记录下来</span>
</span></span><span style="display:flex;"><span>      <span style="color:#66d9ef">with</span> tf<span style="color:#f92672">.</span>name_scope(<span style="color:#e6db74">&#39;linear_compute&#39;</span>):
</span></span><span style="display:flex;"><span>        preactivate <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>matmul(input_tensor, weights) <span style="color:#f92672">+</span> biases
</span></span><span style="display:flex;"><span>        tf<span style="color:#f92672">.</span>summary<span style="color:#f92672">.</span>histogram(<span style="color:#e6db74">&#39;linear&#39;</span>, preactivate)
</span></span><span style="display:flex;"><span>      <span style="color:#75715e"># 将线性输出经过激励函数，并将输出也用直方图记录下来</span>
</span></span><span style="display:flex;"><span>      activations <span style="color:#f92672">=</span> act(preactivate, name<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;activation&#39;</span>)
</span></span><span style="display:flex;"><span>      tf<span style="color:#f92672">.</span>summary<span style="color:#f92672">.</span>histogram(<span style="color:#e6db74">&#39;activations&#39;</span>, activations)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>      <span style="color:#75715e"># 返回激励层的最终输出</span>
</span></span><span style="display:flex;"><span>      <span style="color:#66d9ef">return</span> activations
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>hidden1 <span style="color:#f92672">=</span> nn_layer(x, <span style="color:#ae81ff">784</span>, <span style="color:#ae81ff">500</span>, <span style="color:#e6db74">&#39;layer1&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">with</span> tf<span style="color:#f92672">.</span>name_scope(<span style="color:#e6db74">&#39;dropout&#39;</span>):
</span></span><span style="display:flex;"><span>    keep_prob <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>placeholder(tf<span style="color:#f92672">.</span>float32)
</span></span><span style="display:flex;"><span>    tf<span style="color:#f92672">.</span>summary<span style="color:#f92672">.</span>scalar(<span style="color:#e6db74">&#39;dropout_keep_probability&#39;</span>, keep_prob)
</span></span><span style="display:flex;"><span>    dropped <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>dropout(hidden1, keep_prob)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>y <span style="color:#f92672">=</span> nn_layer(dropped, <span style="color:#ae81ff">500</span>, <span style="color:#ae81ff">10</span>, <span style="color:#e6db74">&#39;layer2&#39;</span>, act<span style="color:#f92672">=</span>tf<span style="color:#f92672">.</span>identity)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">with</span> tf<span style="color:#f92672">.</span>name_scope(<span style="color:#e6db74">&#39;loss&#39;</span>):
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 计算交叉熵损失（每个样本都会有一个损失）</span>
</span></span><span style="display:flex;"><span>    diff <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>softmax_cross_entropy_with_logits(labels<span style="color:#f92672">=</span>y_, logits<span style="color:#f92672">=</span>y)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">with</span> tf<span style="color:#f92672">.</span>name_scope(<span style="color:#e6db74">&#39;total&#39;</span>):
</span></span><span style="display:flex;"><span>      <span style="color:#75715e"># 计算所有样本交叉熵损失的均值</span>
</span></span><span style="display:flex;"><span>      cross_entropy <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>reduce_mean(diff)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>tf<span style="color:#f92672">.</span>summary<span style="color:#f92672">.</span>scalar(<span style="color:#e6db74">&#39;loss&#39;</span>, cross_entropy)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">with</span> tf<span style="color:#f92672">.</span>name_scope(<span style="color:#e6db74">&#39;train&#39;</span>):
</span></span><span style="display:flex;"><span>    train_step <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>train<span style="color:#f92672">.</span>AdamOptimizer(learning_rate)<span style="color:#f92672">.</span>minimize(
</span></span><span style="display:flex;"><span>        cross_entropy)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">with</span> tf<span style="color:#f92672">.</span>name_scope(<span style="color:#e6db74">&#39;accuracy&#39;</span>):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">with</span> tf<span style="color:#f92672">.</span>name_scope(<span style="color:#e6db74">&#39;correct_prediction&#39;</span>):
</span></span><span style="display:flex;"><span>      <span style="color:#75715e"># 分别将预测和真实的标签中取出最大值的索引，弱相同则返回1(true),不同则返回0(false)</span>
</span></span><span style="display:flex;"><span>      correct_prediction <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>equal(tf<span style="color:#f92672">.</span>argmax(y, <span style="color:#ae81ff">1</span>), tf<span style="color:#f92672">.</span>argmax(y_, <span style="color:#ae81ff">1</span>))
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">with</span> tf<span style="color:#f92672">.</span>name_scope(<span style="color:#e6db74">&#39;accuracy&#39;</span>):
</span></span><span style="display:flex;"><span>      <span style="color:#75715e"># 求均值即为准确率</span>
</span></span><span style="display:flex;"><span>      accuracy <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>reduce_mean(tf<span style="color:#f92672">.</span>cast(correct_prediction, tf<span style="color:#f92672">.</span>float32))
</span></span><span style="display:flex;"><span>tf<span style="color:#f92672">.</span>summary<span style="color:#f92672">.</span>scalar(<span style="color:#e6db74">&#39;accuracy&#39;</span>, accuracy)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># summaries合并</span>
</span></span><span style="display:flex;"><span>merged <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>summary<span style="color:#f92672">.</span>merge_all()
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 写到指定的磁盘路径中</span>
</span></span><span style="display:flex;"><span>train_writer <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>summary<span style="color:#f92672">.</span>FileWriter(log_dir <span style="color:#f92672">+</span> <span style="color:#e6db74">&#39;/train&#39;</span>, sess<span style="color:#f92672">.</span>graph)
</span></span><span style="display:flex;"><span>test_writer <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>summary<span style="color:#f92672">.</span>FileWriter(log_dir <span style="color:#f92672">+</span> <span style="color:#e6db74">&#39;/test&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 运行初始化所有变量</span>
</span></span><span style="display:flex;"><span>tf<span style="color:#f92672">.</span>global_variables_initializer()<span style="color:#f92672">.</span>run()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">feed_dict</span>(train):
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;&#34;&#34;Make a TensorFlow feed_dict: maps data onto Tensor placeholders.&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> train:
</span></span><span style="display:flex;"><span>      xs, ys <span style="color:#f92672">=</span> mnist<span style="color:#f92672">.</span>train<span style="color:#f92672">.</span>next_batch(<span style="color:#ae81ff">100</span>)
</span></span><span style="display:flex;"><span>      k <span style="color:#f92672">=</span> dropout
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">else</span>:
</span></span><span style="display:flex;"><span>      xs, ys <span style="color:#f92672">=</span> mnist<span style="color:#f92672">.</span>test<span style="color:#f92672">.</span>images, mnist<span style="color:#f92672">.</span>test<span style="color:#f92672">.</span>labels
</span></span><span style="display:flex;"><span>      k <span style="color:#f92672">=</span> <span style="color:#ae81ff">1.0</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> {x: xs, y_: ys, keep_prob: k}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(max_steps):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> i <span style="color:#f92672">%</span> <span style="color:#ae81ff">10</span> <span style="color:#f92672">==</span> <span style="color:#ae81ff">0</span>:  <span style="color:#75715e"># 记录测试集的summary与accuracy</span>
</span></span><span style="display:flex;"><span>      summary, acc <span style="color:#f92672">=</span> sess<span style="color:#f92672">.</span>run([merged, accuracy], feed_dict<span style="color:#f92672">=</span>feed_dict(<span style="color:#66d9ef">False</span>))
</span></span><span style="display:flex;"><span>      test_writer<span style="color:#f92672">.</span>add_summary(summary, i)
</span></span><span style="display:flex;"><span>      print(<span style="color:#e6db74">&#39;Accuracy at step </span><span style="color:#e6db74">%s</span><span style="color:#e6db74">: </span><span style="color:#e6db74">%s</span><span style="color:#e6db74">&#39;</span> <span style="color:#f92672">%</span> (i, acc))
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">else</span>:  <span style="color:#75715e"># 记录训练集的summary</span>
</span></span><span style="display:flex;"><span>      <span style="color:#66d9ef">if</span> i <span style="color:#f92672">%</span> <span style="color:#ae81ff">100</span> <span style="color:#f92672">==</span> <span style="color:#ae81ff">99</span>:  <span style="color:#75715e"># Record execution stats</span>
</span></span><span style="display:flex;"><span>        run_options <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>RunOptions(trace_level<span style="color:#f92672">=</span>tf<span style="color:#f92672">.</span>RunOptions<span style="color:#f92672">.</span>FULL_TRACE)
</span></span><span style="display:flex;"><span>        run_metadata <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>RunMetadata()
</span></span><span style="display:flex;"><span>        summary, _ <span style="color:#f92672">=</span> sess<span style="color:#f92672">.</span>run([merged, train_step],
</span></span><span style="display:flex;"><span>                              feed_dict<span style="color:#f92672">=</span>feed_dict(<span style="color:#66d9ef">True</span>),
</span></span><span style="display:flex;"><span>                              options<span style="color:#f92672">=</span>run_options,
</span></span><span style="display:flex;"><span>                              run_metadata<span style="color:#f92672">=</span>run_metadata)
</span></span><span style="display:flex;"><span>        train_writer<span style="color:#f92672">.</span>add_run_metadata(run_metadata, <span style="color:#e6db74">&#39;step</span><span style="color:#e6db74">%03d</span><span style="color:#e6db74">&#39;</span> <span style="color:#f92672">%</span> i)
</span></span><span style="display:flex;"><span>        train_writer<span style="color:#f92672">.</span>add_summary(summary, i)
</span></span><span style="display:flex;"><span>        print(<span style="color:#e6db74">&#39;Adding run metadata for&#39;</span>, i)
</span></span><span style="display:flex;"><span>      <span style="color:#66d9ef">else</span>:  <span style="color:#75715e"># Record a summary</span>
</span></span><span style="display:flex;"><span>        summary, _ <span style="color:#f92672">=</span> sess<span style="color:#f92672">.</span>run([merged, train_step], feed_dict<span style="color:#f92672">=</span>feed_dict(<span style="color:#66d9ef">True</span>))
</span></span><span style="display:flex;"><span>        train_writer<span style="color:#f92672">.</span>add_summary(summary, i)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>train_writer<span style="color:#f92672">.</span>close()
</span></span><span style="display:flex;"><span>test_writer<span style="color:#f92672">.</span>close()
</span></span></code></pre></div>
        </div>

        
        
<div class="post-copyright">
  <p class="copyright-item">
    <span class="item-title">Author</span>
    <span class="item-content">Yuanye Ma</span>
  </p>
  <p class="copyright-item">
    <span class="item-title">LastMod</span>
    <span class="item-content">
      2019-04-15
      
    </span>
  </p>
  
  <p class="copyright-item">
    <span class="item-title">License</span>
    <span class="item-content"><a href="https://github.com/gohugoio/hugoBasicExample" rel="noopener" target="_blank">See origin</a></span>
  </p>
</div>



        
        


        <footer class="post-footer">
          <div class="post-tags">
              <a href="http://0.0.0.0:1313/tags/tensorflow/">TensorFlow</a>
                <a href="http://0.0.0.0:1313/tags/tensorboardx/">TensorBoardX</a>
                
            </div>


          
          <nav class="post-nav">
            
              <a class="prev" href="/post/programing/2019-07-29-stl%E5%85%A5%E9%97%A8/">
                
                <i class="iconfont">
                  <svg  class="icon" viewBox="0 0 1024 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="18" height="18">
  <path d="M691.908486 949.511495l75.369571-89.491197c10.963703-12.998035 10.285251-32.864502-1.499144-44.378743L479.499795 515.267417 757.434875 204.940602c11.338233-12.190647 11.035334-32.285311-0.638543-44.850487l-80.46666-86.564541c-11.680017-12.583596-30.356378-12.893658-41.662889-0.716314L257.233596 494.235404c-11.332093 12.183484-11.041474 32.266891 0.657986 44.844348l80.46666 86.564541c1.772366 1.910513 3.706415 3.533476 5.750981 4.877077l306.620399 321.703933C662.505829 963.726242 680.945807 962.528973 691.908486 949.511495z"></path>
</svg>

                </i>
                <span class="prev-text nav-default">STL入门</span>
                <span class="prev-text nav-mobile">Prev</span>
              </a>
            
              <a class="next" href="/post/service/breakwall-3-trojan/">
                <span class="next-text nav-default">Trojan</span>
                <span class="prev-text nav-mobile">Next</span>
                
                <i class="iconfont">
                  <svg class="icon" viewBox="0 0 1024 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="18" height="18">
  <path d="M332.091514 74.487481l-75.369571 89.491197c-10.963703 12.998035-10.285251 32.864502 1.499144 44.378743l286.278095 300.375162L266.565125 819.058374c-11.338233 12.190647-11.035334 32.285311 0.638543 44.850487l80.46666 86.564541c11.680017 12.583596 30.356378 12.893658 41.662889 0.716314l377.434212-421.426145c11.332093-12.183484 11.041474-32.266891-0.657986-44.844348l-80.46666-86.564541c-1.772366-1.910513-3.706415-3.533476-5.750981-4.877077L373.270379 71.774697C361.493148 60.273758 343.054193 61.470003 332.091514 74.487481z"></path>
</svg>

                </i>
              </a>
          </nav>
        </footer>
      </article>

      
      


      
      


    </div>

    
    <nav class="toc" id="toc">
    <div class="toc-title">Table of Contents</div>
    <div class="toc-content custom-scrollbar">
      <nav id="TableOfContents">
  <ul>
    <li><a href="#总结一下tensorboardx的用法">总结一下TensorboardX的用法</a></li>
  </ul>

  <ul>
    <li><a href="#总结一下使用的步骤">总结一下使用的步骤</a></li>
    <li><a href="#参考代码">参考代码</a></li>
  </ul>
</nav>
    </div>
  </nav>


  </div>

      </main>

      <footer id="footer" class="footer">
        <div class="icon-links">
  
  
    <a href="yuanye.ma@qq.com" rel="me noopener" class="iconfont"
      title="email"  target="_blank"
      >
      <svg class="icon" viewBox="0 0 1451 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="36" height="36">
  <path d="M664.781909 681.472759 0 97.881301C0 3.997201 71.046997 0 71.046997 0L474.477909 0 961.649408 0 1361.641813 0C1361.641813 0 1432.688811 3.997201 1432.688811 97.881301L771.345323 681.472759C771.345323 681.472759 764.482731 685.154773 753.594283 688.65053L753.594283 688.664858C741.602731 693.493018 729.424896 695.068979 718.077952 694.839748 706.731093 695.068979 694.553173 693.493018 682.561621 688.664858L682.561621 688.65053C671.644501 685.140446 664.781909 681.472759 664.781909 681.472759L664.781909 681.472759ZM718.063616 811.603883C693.779541 811.016482 658.879232 802.205449 619.10784 767.734955 542.989056 701.759633 0 212.052267 0 212.052267L0 942.809523C0 942.809523 0 1024 83.726336 1024L682.532949 1024 753.579947 1024 1348.948139 1024C1432.688811 1024 1432.688811 942.809523 1432.688811 942.809523L1432.688811 212.052267C1432.688811 212.052267 893.138176 701.759633 817.019477 767.734955 777.248 802.205449 742.347691 811.03081 718.063616 811.603883L718.063616 811.603883Z"></path>
</svg>

    </a>
  
    <a href="https://github.com/YuanyeMa" rel="me noopener" class="iconfont"
      title="github"  target="_blank"
      >
      <svg class="icon" style="" viewBox="0 0 1024 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="36" height="36">
  <path d="M512 12.672c-282.88 0-512 229.248-512 512 0 226.261333 146.688 418.133333 350.08 485.76 25.6 4.821333 34.986667-11.008 34.986667-24.618667 0-12.16-0.426667-44.373333-0.64-87.04-142.421333 30.890667-172.458667-68.693333-172.458667-68.693333C188.672 770.986667 155.008 755.2 155.008 755.2c-46.378667-31.744 3.584-31.104 3.584-31.104 51.413333 3.584 78.421333 52.736 78.421333 52.736 45.653333 78.293333 119.850667 55.68 149.12 42.581333 4.608-33.109333 17.792-55.68 32.426667-68.48-113.706667-12.8-233.216-56.832-233.216-253.013333 0-55.893333 19.84-101.546667 52.693333-137.386667-5.76-12.928-23.04-64.981333 4.48-135.509333 0 0 42.88-13.738667 140.8 52.48 40.96-11.392 84.48-17.024 128-17.28 43.52 0.256 87.04 5.888 128 17.28 97.28-66.218667 140.16-52.48 140.16-52.48 27.52 70.528 10.24 122.581333 5.12 135.509333 32.64 35.84 52.48 81.493333 52.48 137.386667 0 196.693333-119.68 240-233.6 252.586667 17.92 15.36 34.56 46.762667 34.56 94.72 0 68.522667-0.64 123.562667-0.64 140.202666 0 13.44 8.96 29.44 35.2 24.32C877.44 942.592 1024 750.592 1024 524.672c0-282.752-229.248-512-512-512"></path>
</svg>

    </a>
  
    <a href="https://www.zhihu.com/people/mr-kevin-92" rel="me noopener" class="iconfont"
      title="zhihu"  target="_blank"
      >
      <svg class="icon" viewBox="0 0 1024 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="36" height="36">
  <path d="M351.791182 562.469462l192.945407 0c0-45.367257-21.3871-71.939449-21.3871-71.939449L355.897709 490.530013c3.977591-82.182744 7.541767-187.659007 8.816806-226.835262l159.282726 0c0 0-0.86367-67.402109-18.578124-67.402109s-279.979646 0-279.979646 0 16.850783-88.141456 39.318494-127.053698c0 0-83.60514-4.510734-112.121614 106.962104S81.344656 355.077018 76.80834 367.390461c-4.536316 12.313443 24.62791 5.832845 36.941354 0 12.313443-5.832845 68.050885-25.924439 84.252893-103.69571l86.570681 0c1.165546 49.28652 4.596691 200.335724 3.515057 226.835262L109.86113 490.530013c-25.275663 18.147312-33.701566 71.939449-33.701566 71.939449L279.868105 562.469462c-8.497535 56.255235-23.417339 128.763642-44.275389 167.210279-33.05279 60.921511-50.55235 116.65793-169.802314 212.576513 0 0-19.442818 14.257725 40.829917 9.073656 60.273758-5.185093 117.305683-20.739347 156.840094-99.807147 20.553105-41.107233 41.805128-93.250824 58.386782-146.138358l-0.055259 0.185218 167.855986 193.263655c0 0 22.035876-51.847855 5.832845-108.880803L371.045711 650.610918l-42.1244 31.157627-0.045025 0.151449c11.69946-41.020252 20.11206-81.5749 22.726607-116.858498C351.665315 564.212152 351.72876 563.345412 351.791182 562.469462z"></path>
  <path d="M584.918753 182.033893l0 668.840094 70.318532 0 28.807093 80.512708 121.875768-80.512708 153.600307 0L959.520453 182.033893 584.918753 182.033893zM887.150192 778.934538l-79.837326 0-99.578949 65.782216-23.537066-65.782216-24.855084 0L659.341766 256.673847l227.807403 0L887.149169 778.934538z"></path>
</svg>

    </a>
  
    <a href="https://space.bilibili.com/159072924?spm_id_from=333.1007.0.0" rel="me noopener" class="iconfont"
      title="bilibili"  target="_blank"
      >
      <svg
  class="icon" style="" viewBox="0 0 1024 1024" version="1.1" width="36"
  height="36" id="svg8">
  <path
      style=""
      d="M 744.60599,0.00486267 A 41.779915,41.779915 0 0 0 710.4184,18.673394 L 548.5048,255.32642 h -11.70046 a 41.779915,41.779915 0 0 0 -10.80295,-7.84928 L 235.66,97.084498 a 41.779915,41.779915 0 0 0 -20.07193,-4.960864 41.779915,41.779915 0 0 0 -18.3748,79.145436 L 359.4859,255.32642 H 128.16909 c -49.458302,0 -89.27932,39.82105 -89.27932,89.27932 v 508.65224 c 0,49.4583 39.821018,89.27934 89.27932,89.27934 h 19.48445 C 149.12802,984.5043 179.92773,1024 224.79179,1024 c 44.86407,0 75.66379,-39.4957 77.13826,-81.46268 H 719.98116 C 721.45559,984.5043 752.25533,1024 797.1194,1024 c 44.86406,0 75.6638,-39.4957 77.13824,-81.46268 h 21.57323 c 49.45831,0 89.27936,-39.82104 89.27936,-89.27934 V 344.60574 c 0,-49.45827 -39.82105,-89.27932 -89.27936,-89.27932 H 649.74567 L 779.38103,65.866924 A 41.779915,41.779915 0 0 0 744.60599,0.00486267 Z M 644.49108,418.70871 c 6.29985,0.21538 12.44451,2.01107 17.86888,5.22196 l 171.36218,98.10771 c 18.23417,10.21935 24.63334,33.34627 14.24614,51.48533 -10.38726,18.13909 -33.57344,24.32718 -51.61587,13.77296 L 624.9903,489.18895 c -15.21356,-8.41858 -22.66871,-26.1765 -18.03211,-42.93436 4.63664,-16.75784 20.15573,-28.14465 37.53289,-27.54588 z M 350.2006,432.31846 c 16.89952,0.0317 31.69582,11.33328 36.17844,27.62747 4.48262,16.2942 -2.44981,33.57765 -16.95507,42.24898 l -140.7157,86.91312 c -17.68528,11.18244 -41.09629,5.77692 -52.08912,-12.02686 -10.99282,-17.80373 -5.33855,-41.15658 12.58167,-51.95857 L 329.9002,438.2095 c 6.0643,-3.86439 13.10951,-5.90891 20.3004,-5.89104 z M 501.605,641.53985 c 3.75002,-0.15248 7.48645,0.53903 10.93349,2.0235 0.15842,0.0637 0.31618,0.12888 0.47325,0.19582 0.59328,0.27092 1.17574,0.56489 1.74609,0.88121 0.15868,0.0854 0.31643,0.17233 0.47325,0.2611 0.55694,0.32165 1.10131,0.66458 1.63185,1.02807 0.16455,0.1123 0.32777,0.2265 0.48956,0.34269 0.50382,0.36781 0.99371,0.75428 1.46868,1.15864 0.18724,0.15504 0.37218,0.31282 0.55484,0.47323 0.43271,0.38784 0.8518,0.79061 1.25653,1.20756 0.15449,0.16114 0.30679,0.32437 0.45693,0.48959 0.40798,0.44266 0.79989,0.89988 1.17494,1.37076 0.17799,0.22544 0.35205,0.45395 0.5222,0.68538 0.25932,0.34701 0.50964,0.70071 0.75064,1.06071 0.26712,0.39516 0.52286,0.79784 0.76699,1.20757 0.16907,0.29043 0.33231,0.58424 0.48957,0.88123 0.21836,0.41297 0.42513,0.83199 0.62009,1.25653 0.14836,0.32333 0.28983,0.64976 0.42429,0.97911 0.21319,0.51552 0.40915,1.03801 0.58747,1.5666 0.0677,0.19499 0.13296,0.39085 0.19582,0.58748 0.18652,0.60823 0.34984,1.22334 0.48957,1.84399 0.0397,0.16277 0.0779,0.32601 0.11423,0.48957 0.1436,0.69112 0.25788,1.38801 0.34269,2.08877 0.005,0.0381 0.0111,0.0761 0.0163,0.11424 0.0857,0.78056 0.13474,1.56471 0.14687,2.34988 0.005,0.0543 0.0111,0.10879 0.0163,0.1632 0,0 -0.008,1.12132 0,1.45234 0,0 -0.14697,17.84761 5.89102,34.12231 3.01902,8.13734 7.33278,15.10615 12.61433,19.61501 5.28157,4.50889 11.42894,7.62081 23.64572,7.62081 12.2168,0 18.36416,-3.11192 23.64573,-7.62081 5.28154,-4.50886 9.5953,-11.47767 12.6143,-19.61501 6.03799,-16.2747 5.89103,-34.12231 5.89103,-34.12231 -0.44885,-13.87045 10.45922,-25.46302 24.3311,-25.86506 13.87189,-0.40201 25.42828,10.53953 25.78348,24.41272 0,0 1.11929,25.7226 -9.00791,53.01927 -5.06359,13.64832 -13.1986,28.46036 -27.05631,40.29073 -13.85772,11.83039 -33.5454,19.63135 -56.20142,19.63135 -22.65603,0 -42.34371,-7.80096 -56.20141,-19.63135 -4.1801,-3.56856 -7.78733,-7.42433 -10.99878,-11.42303 -3.21235,4.00037 -6.81703,7.85309 -10.99876,11.42303 -13.85773,11.83039 -33.5454,19.63135 -56.20144,19.63135 -22.65601,0 -42.3437,-7.80096 -56.2014,-19.63135 -13.85775,-11.83037 -21.99272,-26.64241 -27.05632,-40.29073 -10.12725,-27.29667 -9.00789,-53.01928 -9.00789,-53.01927 0.20714,-13.83687 11.58744,-24.88848 25.42444,-24.69013 14.1263,0.19991 25.2971,12.0278 24.69011,26.14247 0,0 -0.14697,17.84761 5.89103,34.12231 3.01902,8.13734 7.31646,15.10615 12.598,19.61501 5.28155,4.50889 11.44526,7.62081 23.66203,7.62081 12.21681,0 18.36418,-3.11192 23.64573,-7.62081 5.28154,-4.50886 9.57899,-11.47767 12.598,-19.61501 5.76352,-15.53489 5.89112,-32.05691 5.89103,-33.56746 0.006,-0.37466 0.0111,-1.05336 0.0163,-1.20759 -0.0117,-0.74583 0.0105,-1.49177 0.0652,-2.23565 0.009,-0.15784 0.0204,-0.31561 0.0327,-0.47324 0.14204,-1.56859 0.43163,-3.12027 0.86487,-4.63449 0.0213,-0.0763 0.0433,-0.15244 0.0652,-0.22848 3.0335,-10.25748 12.24157,-17.46007 22.92769,-17.93417 z"
      id="rect824"/>
</svg>

    </a>


<a href="http://0.0.0.0:1313/index.xml" rel="noopener alternate" type="application/rss&#43;xml"
    class="iconfont" title="rss" target="_blank">
    <svg class="icon" viewBox="0 0 1024 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="30" height="30">
  <path d="M819.157333 1024C819.157333 574.592 449.408 204.8 0 204.8V0c561.706667 0 1024 462.293333 1024 1024h-204.842667zM140.416 743.04a140.8 140.8 0 0 1 140.501333 140.586667A140.928 140.928 0 0 1 140.074667 1024C62.72 1024 0 961.109333 0 883.626667s62.933333-140.544 140.416-140.586667zM678.784 1024h-199.04c0-263.210667-216.533333-479.786667-479.744-479.786667V345.173333c372.352 0 678.784 306.517333 678.784 678.826667z"></path>
</svg>

  </a>
  
</div>

<div class="copyright">
  <span class="power-by">
    Powered by <a class="hexo-link" href="https://gohugo.io">Hugo</a>
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    Theme - <a class="theme-link" href="https://github.com/xianmin/hugo-theme-jane">Jane</a>
  </span>

  <span class="copyright-year">
    &copy;
    2024
    <span class="heart">
      
      <i class="iconfont">
        <svg class="icon" viewBox="0 0 1025 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="14" height="14">
  <path d="M1000.1 247.9c-15.5-37.3-37.6-70.6-65.7-98.9-54.4-54.8-125.8-85-201-85-85.7 0-166 39-221.4 107.4C456.6 103 376.3 64 290.6 64c-75.1 0-146.5 30.4-201.1 85.6-28.2 28.5-50.4 61.9-65.8 99.3-16 38.8-24 79.9-23.6 122.2 0.7 91.7 40.1 177.2 108.1 234.8 3.1 2.6 6 5.1 8.9 7.8 14.9 13.4 58 52.8 112.6 102.7 93.5 85.5 209.9 191.9 257.5 234.2 7 6.1 15.8 9.5 24.9 9.5 9.2 0 18.1-3.4 24.9-9.5 34.5-30.7 105.8-95.9 181.4-165 74.2-67.8 150.9-138 195.8-178.2 69.5-57.9 109.6-144.4 109.9-237.3 0.1-42.5-8-83.6-24-122.2z"
   fill="#8a8a8a"></path>
</svg>

      </i>
    </span><span class="author">
        Yuanye Ma
        
      </span></span>

  
  

  
</div>

      </footer>

      <div class="button__back-to-top">
        <a href="#back-to-top">
          <i class="iconfont">
            
            <svg class="icon" viewBox="0 0 1024 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="35" height="35">
  <path d="M510.866688 227.694839 95.449397 629.218702l235.761562 0-2.057869 328.796468 362.40389 0L691.55698 628.188232l241.942331-3.089361L510.866688 227.694839zM63.840492 63.962777l894.052392 0 0 131.813095L63.840492 195.775872 63.840492 63.962777 63.840492 63.962777zM63.840492 63.962777"></path>
</svg>

          </i>
        </a>
      </div>
    </div>
    
<script type="text/javascript" src="/lib/jquery/jquery-3.7.1.min.js"></script>
  <script type="text/javascript" src="/lib/slideout/slideout-1.0.1.min.js"></script>




<script type="text/javascript" src="/js/main.823efc68a3fe47916871970a683c47e53fce8735cd7c97764a761f2043c82f7e.js" integrity="sha256-gj78aKP&#43;R5FocZcKaDxH5T/OhzXNfJd2SnYfIEPIL34=" crossorigin="anonymous"></script>



  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>










  
    <script type="text/javascript" src="/lib/photoswipe/photoswipe.min.js"></script>
    <script type="text/javascript" src="/lib/photoswipe/photoswipe-ui-default.min.js"></script>
  

















  </body>
</html>
